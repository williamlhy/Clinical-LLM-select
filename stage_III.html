<!DOCTYPE html>
<html lang="en">
<head>
	<meta charset="utf-8">
	<meta name="viewport"    content="width=device-width, initial-scale=1.0">
	<meta name="description" content="">
	<meta name="author"      content="Hongyi Li">
	
	<title>Stage III | Clinical LLM selector</title>

	<link rel="shortcut icon" href="assets/images/gt_favicon.png">
	
	<!-- Bootstrap -->
	<link href="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.no-icons.min.css" rel="stylesheet">
	<!-- Icon font -->
	<link href="https://netdna.bootstrapcdn.com/font-awesome/4.0.3/css/font-awesome.css" rel="stylesheet">
	<!-- Fonts -->
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Alice|Open+Sans:400,300,700">
	<!-- Custom styles -->
	<link rel="stylesheet" href="assets/css/styles.css">

	<!--[if lt IE 9]> <script src="assets/js/html5shiv.js"></script> <![endif]-->
</head>
<body>

    <header id="header">
        <div id="head" class="parallax" parallax-speed="2">
            <h1 id="logo" class="text-center">
                <img class="img-circle" src="assets/images/me.jpg" alt="">
                <span class="title">Hongyi Li</span>
                <span class="tagline">Zhejiang University<br>
                    <a href="">12135029@zju.edu.cn</a></span>
            </h1>
        </div>
    
        <nav class="navbar navbar-default navbar-sticky">
            <div class="container-fluid">
                
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button>
                </div>
                
                <div class="navbar-collapse collapse">
                    
                    <ul class="nav navbar-nav">
                        <li class="active"><a href="index.html">Home</a></li>
                        <li><a href="about.html">About</a></li>
                        <li class="dropdown">
                            <a href="#" class="dropdown-toggle" data-toggle="dropdown">Clinical LLM selector <b class="caret"></b></a>
                            <ul class="dropdown-menu">
                                <li><a href="intro.html">Introduction</a></li>
                                <li><a href="guideline.html">Guideline</a></li>
                                <li><a href="stage_I.html">Stage_I</a></li>
                                <li><a href="stage_II.html">Stage_II</a></li>
                                <li><a href="stage_III.html">Stage_III</a></li>
                                <li><a href="stage_IV.html">Stage_IV</a></li>
                                <li><a href="stage_V.html">Stage_V</a></li>
                            </ul>
                        </li>
                        <!-- <li><a href="blog.html">Blog</a></li> -->
                    </ul>
                
                </div><!--/.nav-collapse -->			
            </div>	
        </nav>
    </header>

<main id="main">
    <div class="container">
		<div class="row topspace">
			<div class="col-sm-8 col-sm-offset-2">
															
				<article class="post">
					<header class="entry-header">
						<div class="entry-meta"> 
							<!-- <span class="posted-on"><time class="entry-date published" date="2024-10-29">October 29, 2024</time></span>			 -->
						</div>
						<h1 class="entry-title"><a href="single.html" rel="bookmark">Clinical LLM srlector for stage III</a></h1>
					</header>
					<div class="entry-content">
						<p><b>Stage III: diagnosis and treatment planning.</b>
                        <br>Next, answer the following questions to find the most suitable LLM for your use case. If an answer has an LLM followed by an `(*)' sign, this indicates that papers reported (not necessarily the same papers) that the LLM was the best performing LLM in the selected condition. e.g. there may be three different papers reporting the same LLM as the best performing model in three different clinical tasks, so when `Yes' is selected for all three clinical tasks, the answer will have the name of that LLM followed by the `(*)'. Those without the `(*)' are simply LLMs that satisfy the selected condition.<br>
                        <span style="color: blue;">Blue text</span> that appears in a question indicates that a specific explanation is available by clicking on that text. The explanation will appear at the bottom of the page and can be closed by clicking red `close' in the explanation.<br>
                        <span style="color: rgb(141, 40, 224);">Any links</span> present in the answer can be accessed by clicking on them.</p>
					</div>
                    <h5>Please answer the following questions on a case-by-case basis.</h5>
                    <!-- <div class="buttonContainer">
                        <button onclick="loadContent('LLM.html')">Return to the initial screen </button>
                    </div> -->
                
                    <div id="questionContainer"></div>
                    <div id="descriptionContainer">
                        <p id="descriptionText"></p>
                        <span id="closeButton">Close</span>
                    </div>
                    <p></p>
				</article>
			</div> 
		</div>


</main>

<footer id="footer">
	<div class="container">
		<div class="row">
			<div class="col-md-3 widget">
				<h3 class="widget-title">Contact</h3>
				<div class="widget-body">
						<a href="mailto:#">12135029@zju.edu.cn</a><br>
						<br>
						Zhejiang University, HangZhou, China
					</p>	
				</div>
			</div>

			<div class="col-md-3 widget">
				<h3 class="widget-title">Follow me</h3>
				<div class="widget-body">
					<p class="follow-me-icons">
						<a href="https://github.com/williamlhy"><i class="fa fa-github fa-2"></i></a>
					</p>
				</div>
			</div>

			<!-- <div class="col-md-3 widget">
				<h3 class="widget-title">Text widget</h3>
				<div class="widget-body">
					<p>Require to fill</p>
				</div>
			</div>

			<div class="col-md-3 widget">
				<h3 class="widget-title">Form widget</h3>
				<div class="widget-body">
					<p>+234 23 9873237<br>
						<a href="mailto:#">some.email@somewhere.com</a><br>
						<br>
						234 Hidden Pond Road, Ashland City, TN 37015
					</p>	
				</div>
			</div> -->

		</div> <!-- /row of widgets -->
	</div>
</footer>

<footer id="underfooter">
	<div class="container">
		<div class="row">
			
			<div class="col-md-6 widget">
				<div class="widget-body">
					<p>Zhejiang University, HangZhou, China </p>
				</div>
			</div>

			<div class="col-md-6 widget">
				<div class="widget-body">
					<p class="text-right">
						Copyright &copy; 2024, Hongyi Li</p>
				</div>
			</div>

		</div> <!-- /row of widgets -->
	</div>
</footer>



<!-- JavaScript libs are placed at the end of the document so the pages load faster -->
<script>document.addEventListener('DOMContentLoaded', function () {
    const data = {
        "0": {
            "question": "Does your input include only <span class='highlight' data-keyword='textual data'>textual data</span>?",
            "yes": "1",
            "no": "2"
        },
        "1": {
            "question": "Does your output include only <span class='highlight' data-keyword='textual data'>textual data</span>?",
            "yes": "3",
            "no": "4"
        },
        "2": {
            "question": "Does your output include only <span class='highlight' data-keyword='textual data'>textual data</span>?",
            "yes": "5",
            "no": "6"
        },
        "3": {
            "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
            "yes": "7",
            "no": "8"
        },
        "4": {
            "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
            "yes": "9",
            "no": "10"
        },
        "5": {
            "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
            "yes": "11",
            "no": "12"
        },
        "6": {
            "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
            "yes": "13",
            "no": "14"
        },
        "7": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 7",
            "yes": "15",
            "no": "16"
        },
        "8": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 8",
            "yes": "17",
            "no": "18"
        },
        "9": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 9",
            "yes": "19",
            "no": "20"
        },
        "10": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 10",
            "yes": "21",
            "no": "22"
        },
        "11": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 11",
            "yes": "23",
            "no": "24"
        },
        "12": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 12",
            "yes": "25",
            "no": "26"
        },
        "13": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 13",
            "yes": "27",
            "no": "28"
        },
        "14": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='perform tasks related to disease diagnosis'>perform tasks related to disease diagnosis</span>? 14",
            "yes": "29",
            "no": "30"
        },
        "15": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 15",
            "yes": "31",
            "no": "32"
        },
        "16": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 16",
            "yes": "33",
            "no": "34"
        },
        "17": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 17",
            "yes": "35",
            "no": "36"
        },
        "18": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 18",
            "yes": "37",
            "no": "38"
        },
        "19": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 19",
            "yes": "39",
            "no": "40"
        },
        "20": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 20",
            "yes": "41",
            "no": "42"
        },
        "21": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 21",
            "yes": "43",
            "no": "44"
        },
        "22": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 22",
            "yes": "45",
            "no": "46"
        },
        "23": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 23",
            "yes": "47",
            "no": "48"
        },
        "24": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 24",
            "yes": "49",
            "no": "50"
        },
        "25": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 25",
            "yes": "51",
            "no": "52"
        },
        "26": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 26",
            "yes": "53",
            "no": "54"
        },
        "27": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 27",
            "yes": "55",
            "no": "56"
        },
        "28": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 28",
            "yes": "57",
            "no": "58"
        },
        "29": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 29",
            "yes": "59",
            "no": "60"
        },
        "30": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='extract medical information'>extract medical information</span>? 30",
            "yes": "61",
            "no": "62"
        },
        "31": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 31",
            "yes": "63",
            "no": "64"
        },
        "32": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 32",
            "yes": "65",
            "no": "66"
        },
        "33": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 33",
            "yes": "67",
            "no": "68"
        },
        "34": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 34",
            "yes": "69",
            "no": "70"
        },
        "35": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 35",
            "yes": "71",
            "no": "72"
        },
        "36": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 36",
            "yes": "73",
            "no": "74"
        },
        "37": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 37",
            "yes": "75",
            "no": "76"
        },
        "38": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 38",
            "yes": "77",
            "no": "78"
        },
        "39": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 39",
            "yes": "79",
            "no": "80"
        },
        "40": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 40",
            "yes": "81",
            "no": "82"
        },
        "41": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 41",
            "yes": "83",
            "no": "84"
        },
        "42": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 42",
            "yes": "85",
            "no": "86"
        },
        "43": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 43",
            "yes": "87",
            "no": "88"
        },
        "44": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 44",
            "yes": "89",
            "no": "90"
        },
        "45": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 45",
            "yes": "91",
            "no": "92"
        },
        "46": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 46",
            "yes": "93",
            "no": "94"
        },
        "47": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 47",
            "yes": "95",
            "no": "96"
        },
        "48": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 48",
            "yes": "97",
            "no": "98"
        },
        "49": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 49",
            "yes": "99",
            "no": "100"
        },
        "50": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 50",
            "yes": "101",
            "no": "102"
        },
        "51": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 51",
            "yes": "103",
            "no": "104"
        },
        "52": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 52",
            "yes": "105",
            "no": "106"
        },
        "53": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 53",
            "yes": "107",
            "no": "108"
        },
        "54": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 54",
            "yes": "109",
            "no": "110"
        },
        "55": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 55",
            "yes": "111",
            "no": "112"
        },
        "56": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 56",
            "yes": "113",
            "no": "114"
        },
        "57": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 57",
            "yes": "115",
            "no": "116"
        },
        "58": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 58",
            "yes": "117",
            "no": "118"
        },
        "59": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 59",
            "yes": "119",
            "no": "120"
        },
        "60": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 60",
            "yes": "121",
            "no": "122"
        },
        "61": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 61",
            "yes": "123",
            "no": "124"
        },
        "62": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='answer medical questions'>answer medical questions</span>? 62",
            "yes": "125",
            "no": "126"
        },
        "63": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 63",
            "yes": "127",
            "no": "128"
        },
        "64": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 64",
            "yes": "129",
            "no": "130"
        },
        "65": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 65",
            "yes": "131",
            "no": "132"
        },
        "66": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 66",
            "yes": "133",
            "no": "134"
        },
        "67": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 67",
            "yes": "135",
            "no": "136"
        },
        "68": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 68",
            "yes": "137",
            "no": "138"
        },
        "69": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 69",
            "yes": "139",
            "no": "140"
        },
        "70": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 70",
            "yes": "141",
            "no": "142"
        },
        "71": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 71",
            "yes": "143",
            "no": "144"
        },
        "72": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 72",
            "yes": "145",
            "no": "146"
        },
        "73": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 73",
            "yes": "147",
            "no": "148"
        },
        "74": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 74",
            "yes": "149",
            "no": "150"
        },
        "75": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 75",
            "yes": "151",
            "no": "152"
        },
        "76": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 76",
            "yes": "153",
            "no": "154"
        },
        "77": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 77",
            "yes": "155",
            "no": "156"
        },
        "78": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 78",
            "yes": "157",
            "no": "158"
        },
        "79": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 79",
            "yes": "159",
            "no": "160"
        },
        "80": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 80",
            "yes": "161",
            "no": "162"
        },
        "81": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 81",
            "yes": "163",
            "no": "164"
        },
        "82": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 82",
            "yes": "165",
            "no": "166"
        },
        "83": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 83",
            "yes": "167",
            "no": "168"
        },
        "84": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 84",
            "yes": "169",
            "no": "170"
        },
        "85": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 85",
            "yes": "171",
            "no": "172"
        },
        "86": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 86",
            "yes": "173",
            "no": "174"
        },
        "87": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 87",
            "yes": "175",
            "no": "176"
        },
        "88": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 88",
            "yes": "177",
            "no": "178"
        },
        "89": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 89",
            "yes": "179",
            "no": "180"
        },
        "90": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 90",
            "yes": "181",
            "no": "182"
        },
        "91": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 91",
            "yes": "183",
            "no": "184"
        },
        "92": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 92",
            "yes": "185",
            "no": "186"
        },
        "93": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 93",
            "yes": "187",
            "no": "188"
        },
        "94": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 94",
            "yes": "189",
            "no": "190"
        },
        "95": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 95",
            "yes": "191",
            "no": "192"
        },
        "96": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 96",
            "yes": "193",
            "no": "194"
        },
        "97": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 97",
            "yes": "195",
            "no": "196"
        },
        "98": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 98",
            "yes": "197",
            "no": "198"
        },
        "99": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 99",
            "yes": "199",
            "no": "200"
        },
        "100": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 100",
            "yes": "201",
            "no": "202"
        },
        "101": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 101",
            "yes": "203",
            "no": "204"
        },
        "102": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 102",
            "yes": "205",
            "no": "206"
        },
        "103": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 103",
            "yes": "207",
            "no": "208"
        },
        "104": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 104",
            "yes": "209",
            "no": "210"
        },
        "105": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 105",
            "yes": "211",
            "no": "212"
        },
        "106": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 106",
            "yes": "213",
            "no": "214"
        },
        "107": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 107",
            "yes": "215",
            "no": "216"
        },
        "108": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 108",
            "yes": "217",
            "no": "218"
        },
        "109": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 109",
            "yes": "219",
            "no": "220"
        },
        "110": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 110",
            "yes": "221",
            "no": "222"
        },
        "111": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 111",
            "yes": "223",
            "no": "224"
        },
        "112": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 112",
            "yes": "225",
            "no": "226"
        },
        "113": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 113",
            "yes": "227",
            "no": "228"
        },
        "114": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 114",
            "yes": "229",
            "no": "230"
        },
        "115": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 115",
            "yes": "231",
            "no": "232"
        },
        "116": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 116",
            "yes": "233",
            "no": "234"
        },
        "117": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 117",
            "yes": "235",
            "no": "236"
        },
        "118": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 118",
            "yes": "237",
            "no": "238"
        },
        "119": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 119",
            "yes": "239",
            "no": "240"
        },
        "120": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 120",
            "yes": "241",
            "no": "242"
        },
        "121": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 121",
            "yes": "243",
            "no": "244"
        },
        "122": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 122",
            "yes": "245",
            "no": "246"
        },
        "123": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 123",
            "yes": "247",
            "no": "248"
        },
        "124": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 124",
            "yes": "249",
            "no": "250"
        },
        "125": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 125",
            "yes": "251",
            "no": "252"
        },
        "126": {
            "question": "Do you need LLM to be able to <span class='highlight' data-keyword='generate text related to medical decision making'>generate text related to medical decision making</span>? 126",
            "yes": "253",
            "no": "254"
        },
        "127": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 127",
            "yes": "255",
            "no": "256"
        },
        "128": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 128",
            "yes": "257",
            "no": "258"
        },
        "129": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 129",
            "yes": "259",
            "no": "260"
        },
        "130": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 130",
            "yes": "261",
            "no": "262"
        },
        "131": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 131",
            "yes": "263",
            "no": "264"
        },
        "132": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 132",
            "yes": "265",
            "no": "266"
        },
        "133": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 133",
            "yes": "267",
            "no": "268"
        },
        "134": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 134",
            "yes": "269",
            "no": "270"
        },
        "135": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 135",
            "yes": "271",
            "no": "272"
        },
        "136": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 136",
            "yes": "273",
            "no": "274"
        },
        "137": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 137",
            "yes": "275",
            "no": "276"
        },
        "138": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 138",
            "yes": "277",
            "no": "278"
        },
        "139": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 139",
            "yes": "279",
            "no": "280"
        },
        "140": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 140",
            "yes": "281",
            "no": "282"
        },
        "141": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 141",
            "yes": "283",
            "no": "284"
        },
        "142": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 142"
        },
        "143": {
            "answer": "Sorry, no matching LLMs were found. 143"
        },
        "144": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 144",
            "yes": "289",
            "no": "290"
        },
        "145": {
            "answer": "Sorry, no matching LLMs were found. 145"
        },
        "146": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 146",
            "yes": "293",
            "no": "294"
        },
        "147": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 147",
            "yes": "295",
            "no": "296"
        },
        "148": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 148",
            "yes": "297",
            "no": "298"
        },
        "149": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 149",
            "yes": "299",
            "no": "300"
        },
        "150": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 150",
            "yes": "301",
            "no": "302"
        },
        "151": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 151",
            "yes": "303",
            "no": "304"
        },
        "152": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 152",
            "yes": "305",
            "no": "306"
        },
        "153": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 153",
            "yes": "307",
            "no": "308"
        },
        "154": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 154",
            "yes": "309",
            "no": "310"
        },
        "155": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 155",
            "yes": "311",
            "no": "312"
        },
        "156": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 156",
            "yes": "313",
            "no": "314"
        },
        "157": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 157",
            "yes": "315",
            "no": "316"
        },
        "158": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 158"
        },
        "159": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 159",
            "yes": "319",
            "no": "320"
        },
        "160": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 160",
            "yes": "321",
            "no": "322"
        },
        "161": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 161",
            "yes": "323",
            "no": "324"
        },
        "162": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 162",
            "yes": "325",
            "no": "326"
        },
        "163": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 163",
            "yes": "327",
            "no": "328"
        },
        "164": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 164",
            "yes": "329",
            "no": "330"
        },
        "165": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 165",
            "yes": "331",
            "no": "332"
        },
        "166": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 166",
            "yes": "333",
            "no": "334"
        },
        "167": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 167",
            "yes": "335",
            "no": "336"
        },
        "168": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 168",
            "yes": "337",
            "no": "338"
        },
        "169": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 169",
            "yes": "339",
            "no": "340"
        },
        "170": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 170",
            "yes": "341",
            "no": "342"
        },
        "171": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 171",
            "yes": "343",
            "no": "344"
        },
        "172": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 172",
            "yes": "345",
            "no": "346"
        },
        "173": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 173",
            "yes": "347",
            "no": "348"
        },
        "174": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 174"
        },
        "175": {
            "answer": "Sorry, no matching LLMs were found. 175"
        },
        "176": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 176",
            "yes": "353",
            "no": "354"
        },
        "177": {
            "answer": "Sorry, no matching LLMs were found. 177"
        },
        "178": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 178",
            "yes": "357",
            "no": "358"
        },
        "179": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 179",
            "yes": "359",
            "no": "360"
        },
        "180": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 180",
            "yes": "361",
            "no": "362"
        },
        "181": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 181",
            "yes": "363",
            "no": "364"
        },
        "182": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 182",
            "yes": "365",
            "no": "366"
        },
        "183": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 183",
            "yes": "367",
            "no": "368"
        },
        "184": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 184",
            "yes": "369",
            "no": "370"
        },
        "185": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 185",
            "yes": "371",
            "no": "372"
        },
        "186": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 186",
            "yes": "373",
            "no": "374"
        },
        "187": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 187",
            "yes": "375",
            "no": "376"
        },
        "188": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 188",
            "yes": "377",
            "no": "378"
        },
        "189": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 189",
            "yes": "379",
            "no": "380"
        },
        "190": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 190"
        },
        "191": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 191",
            "yes": "383",
            "no": "384"
        },
        "192": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 192",
            "yes": "385",
            "no": "386"
        },
        "193": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 193",
            "yes": "387",
            "no": "388"
        },
        "194": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 194",
            "yes": "389",
            "no": "390"
        },
        "195": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 195",
            "yes": "391",
            "no": "392"
        },
        "196": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 196",
            "yes": "393",
            "no": "394"
        },
        "197": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 197",
            "yes": "395",
            "no": "396"
        },
        "198": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 198",
            "yes": "397",
            "no": "398"
        },
        "199": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 199",
            "yes": "399",
            "no": "400"
        },
        "200": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 200",
            "yes": "401",
            "no": "402"
        },
        "201": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 201",
            "yes": "403",
            "no": "404"
        },
        "202": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 202",
            "yes": "405",
            "no": "406"
        },
        "203": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 203",
            "yes": "407",
            "no": "408"
        },
        "204": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 204",
            "yes": "409",
            "no": "410"
        },
        "205": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 205",
            "yes": "411",
            "no": "412"
        },
        "206": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 206"
        },
        "207": {
            "answer": "Sorry, no matching LLMs were found. 207"
        },
        "208": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 208",
            "yes": "417",
            "no": "418"
        },
        "209": {
            "answer": "Sorry, no matching LLMs were found. 209"
        },
        "210": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 210",
            "yes": "421",
            "no": "422"
        },
        "211": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 211",
            "yes": "423",
            "no": "424"
        },
        "212": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 212",
            "yes": "425",
            "no": "426"
        },
        "213": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 213",
            "yes": "427",
            "no": "428"
        },
        "214": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 214",
            "yes": "429",
            "no": "430"
        },
        "215": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 215",
            "yes": "431",
            "no": "432"
        },
        "216": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 216",
            "yes": "433",
            "no": "434"
        },
        "217": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 217",
            "yes": "435",
            "no": "436"
        },
        "218": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 218",
            "yes": "437",
            "no": "438"
        },
        "219": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 219",
            "yes": "439",
            "no": "440"
        },
        "220": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 220",
            "yes": "441",
            "no": "442"
        },
        "221": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 221",
            "yes": "443",
            "no": "444"
        },
        "222": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 222"
        },
        "223": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 223",
            "yes": "447",
            "no": "448"
        },
        "224": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 224",
            "yes": "449",
            "no": "450"
        },
        "225": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 225",
            "yes": "451",
            "no": "452"
        },
        "226": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 226",
            "yes": "453",
            "no": "454"
        },
        "227": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 227",
            "yes": "455",
            "no": "456"
        },
        "228": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 228",
            "yes": "457",
            "no": "458"
        },
        "229": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 229",
            "yes": "459",
            "no": "460"
        },
        "230": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 230",
            "yes": "461",
            "no": "462"
        },
        "231": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 231",
            "yes": "463",
            "no": "464"
        },
        "232": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 232",
            "yes": "465",
            "no": "466"
        },
        "233": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 233",
            "yes": "467",
            "no": "468"
        },
        "234": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 234",
            "yes": "469",
            "no": "470"
        },
        "235": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 235",
            "yes": "471",
            "no": "472"
        },
        "236": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 236",
            "yes": "473",
            "no": "474"
        },
        "237": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 237",
            "yes": "475",
            "no": "476"
        },
        "238": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 238"
        },
        "239": {
            "answer": "Sorry, no matching LLMs were found. 239"
        },
        "240": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 240",
            "yes": "481",
            "no": "482"
        },
        "241": {
            "answer": "Sorry, no matching LLMs were found. 241"
        },
        "242": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 242",
            "yes": "485",
            "no": "486"
        },
        "243": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 243",
            "yes": "487",
            "no": "488"
        },
        "244": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 244",
            "yes": "489",
            "no": "490"
        },
        "245": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 245",
            "yes": "491",
            "no": "492"
        },
        "246": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 246",
            "yes": "493",
            "no": "494"
        },
        "247": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 247",
            "yes": "495",
            "no": "496"
        },
        "248": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 248",
            "yes": "497",
            "no": "498"
        },
        "249": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 249",
            "yes": "499",
            "no": "500"
        },
        "250": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 250",
            "yes": "501",
            "no": "502"
        },
        "251": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 251",
            "yes": "503",
            "no": "504"
        },
        "252": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 252",
            "yes": "505",
            "no": "506"
        },
        "253": {
            "question": "Do you prefer to deploy LLM <span class='highlight' data-keyword='locally'>locally</span> rather than <span class='highlight' data-keyword='in the cloud'>in the cloud</span>? 253",
            "yes": "507",
            "no": "508"
        },
        "254": {
            "answer": "Sorry, there is not enough information to recommend LLMs, please select at least one clinical task that requires LLMs to be able to perform. 254"
        },
        "255": {
            "answer": "Sorry, no matching LLMs were found. 255"
        },
        "256": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 256"
        },
        "257": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 257"
        },
        "258": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), Google Bard, GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br> <br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 258"
        },
        "259": {
            "answer": "Sorry, no matching LLMs were found. 259"
        },
        "260": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br>  260"
        },
        "261": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 261"
        },
        "262": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. 262"
        },
        "263": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 263"
        },
        "264": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), MMedIns-Llama 3-8B (*), Google Bard, Claude 3.5 Sonnet, GPT-4o, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br> GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 264"
        },
        "265": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 265"
        },
        "266": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*), Claude 3.5 Sonnet (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens. 266"
        },
        "267": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 267"
        },
        "268": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 268"
        },
        "269": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998. 269"
        },
        "270": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), Claude 3.5 Sonnet (*), GPT-4o (*), Claude 3 Opus (*), GPT-4o1 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Claude 3 Opus: the input price is $0.015/1k tokens and the output price is $0.075/1k tokens.<br><br>GPT-4o1: the input price is $0.015/1k tokens and the output price is $0.06/1k tokens.  270"
        },
        "271": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 271"
        },
        "272": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 272"
        },
        "273": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 273"
        },
        "274": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 274"
        },
        "275": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 275"
        },
        "276": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 276"
        },
        "277": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 277"
        },
        "278": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank' class='custom-link'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.  278"
        },
        "279": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 279"
        },
        "280": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*),MMedIns-Llama 3-8B (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 280"
        },
        "281": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 281"
        },
        "282": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 282"
        },
        "283": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>. <br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 283"
        },
        "284": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), MMedIns-Llama 3-8B (*), GPT-4o (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3.. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens. <br> <br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 284"
        },
        "289": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 289"
        },
        "290": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 290"
        },
        "293": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 293"
        },
        "294": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. 294"
        },
        "295": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 295"
        },
        "296": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 296"
        },
        "297": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  297"
        },
        "298": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 298"
        },
        "299": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  299"
        },
        "300": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 300"
        },
        "301": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998. 301"
        },
        "302": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.  302"
        },
        "303": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  303"
        },
        "304": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  304"
        },
        "305": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 305"
        },
        "306": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 306"
        },
        "307": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  307"
        },
        "308": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  308"
        },
        "309": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 309"
        },
        "310": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 310"
        },
        "311": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 311"
        },
        "312": {
            "answer": "The LLMs we recommend you use are:MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 312"
        },
        "313": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 313"
        },
        "314": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 314"
        },
        "315": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>. <br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 315"
        },
        "316": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 316"
        },
        "319": {
            "answer": "Sorry, no matching LLMs were found. 319"
        },
        "320": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 320"
        },
        "321": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 321"
        },
        "322": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), Google Bard, GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br> <br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 322"
        },
        "323": {
            "answer": "Sorry, no matching LLMs were found. 323"
        },
        "324": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 324"
        },
        "325": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598.  325"
        },
        "326": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. 326"
        },
        "327": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 327"
        },
        "328": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*),MMedIns-Llama 3-8B (*), Google Bard, Claude 3.5 Sonnet, GPT-4o, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br> GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 328"
        },
        "329": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 329"
        },
        "330": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*), Claude 3.5 Sonnet (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens. 330"
        },
        "331": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  331"
        },
        "332": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 332"
        },
        "333": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.  333"
        },
        "334": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), Claude 3.5 Sonnet (*), GPT-4o (*), Claude 3 Opus (*), GPT-4o1 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Claude 3 Opus: the input price is $0.015/1k tokens and the output price is $0.075/1k tokens.<br><br>GPT-4o1: the input price is $0.015/1k tokens and the output price is $0.06/1k tokens. 334"
        },
        "335": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 335"
        },
        "336": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 336"
        },
        "337": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 337"
        },
        "338": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 338"
        },
        "339": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 339"
        },
        "340": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 340"
        },
        "341": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 341"
        },
        "342": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank' class='custom-link'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 342"
        },
        "343": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 343"
        },
        "344": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*),MMedIns-Llama 3-8B (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 344"
        },
        "345": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 345"
        },
        "346": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 346"
        },
        "347": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>. <br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 347"
        },
        "348": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), MMedIns-Llama 3-8B (*), GPT-4o (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3.. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens. <br> <br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 348"
        },
        "353": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 353"
        },
        "354": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 354"
        },
        "357": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 357"
        },
        "358": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Vicuna-13B, Clinical Camel-70B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.  358"
        },
        "359": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  359"
        },
        "360": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 360"
        },
        "361": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 361"
        },
        "362": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 362"
        },
        "363": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  363"
        },
        "364": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  364"
        },
        "365": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998. 365"
        },
        "366": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h. 366"
        },
        "367": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  367"
        },
        "368": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  368"
        },
        "369": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 369"
        },
        "370": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 370"
        },
        "371": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  371"
        },
        "372": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  372"
        },
        "373": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 373"
        },
        "374": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 374"
        },
        "375": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 375"
        },
        "376": {
            "answer": "The LLMs we recommend you use are:MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 376"
        },
        "377": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 377"
        },
        "378": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Xiaoqing (*), OncoGPT-7B (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 378"
        },
        "379": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*),LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>. <br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 379"
        },
        "380": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>For Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, DeepSeek-V3: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  380"
        },
        "383": {
            "answer": "Sorry, no matching LLMs were found. 383"
        },
        "384": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.  384"
        },
        "385": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 385"
        },
        "386": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. 386"
        },
        "387": {
            "answer": "Sorry, no matching LLMs were found. 387"
        },
        "388": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 388"
        },
        "389": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. 389"
        },
        "390": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. 390"
        },
        "391": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 391"
        },
        "392": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GPT-4o (*), MMedIns-Llama 3-8B (*), Google Bard, Claude 3.5 Sonnet, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 392"
        },
        "393": {
            "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Med-Flamingo-7B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 393"
        },
        "394": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*), MMedIns-Llama 3-8B (*), Claude 3.5 Sonnet (*), GPT-4o (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens. 394"
        },
        "395": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 395"
        },
        "396": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GPT-4o (*), MMedIns-Llama 3-8B (*), Google Bard, Claude 3.5 Sonnet, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 396"
        },
        "397": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $72000. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>. 397"
        },
        "398": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*), Claude 3.5 Sonnet (*), GPT-4o (*), Claude 3 Opus (*), Claude 3 Haiku (*), GPT-4o1 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The price of renting 4 this type of GPU using cloud services is $25/1h. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Claude 3 Opus: the input price is $0.015/1k tokens and the output price is $0.075/1k tokens.<br><br>Claude 3 Haiku: the input price is $0.00025/1k tokens and the output price is $0.00125/1k tokens.<br><br>GPT-4o1: the input price is $0.015/1k tokens and the output price is $0.06/1k tokens. 398"
        },
        "399": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 399"
        },
        "400": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 400"
        },
        "401": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> 401"
        },
        "402": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 402"
        },
        "403": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 403"
        },
        "404": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 404"
        },
        "405": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 405"
        },
        "406": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank' class='custom-link'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 406"
        },
        "407": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 407"
        },
        "408": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), MMedIns-Llama 3-8B (*), GPT-4o (*), Google Bard, Claude 3.5 Sonnet, LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 408"
        },
        "409": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*), Xiaoqing-6B (*), OncoGPT-7B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br><br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $31196. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). Fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.  409"
        },
        "410": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*), Xiaoqing-6B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*), Claude 3.5 Sonnet (*), GPT-4o (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br><br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The price of renting GPUs with 192GB of memory using a cloud service is $15/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens. 410"
        },
        "411": {
            "answer": "The LLMs we recommend you use are: Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  411"
        },
        "412": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), GPT-4o (*), Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br> <br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 412"
        },
        "417": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 417"
        },
        "418": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. 418"
        },
        "421": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. 421"
        },
        "422": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. 422"
        },
        "423": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  423"
        },
        "424": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 424"
        },
        "425": {
            "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Med-Flamingo-7B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 425"
        },
        "426": {
            "answer": "The LLMs we recommend you use are: Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 426"
        },
        "427": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  427"
        },
        "428": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 428"
        },
        "429": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $72000. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>. 429"
        },
        "430": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The price of renting 4 this type of GPU using cloud services is $25/1h. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>. 430"
        },
        "431": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  431"
        },
        "432": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  432"
        },
        "433": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 433"
        },
        "434": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 434"
        },
        "435": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  435"
        },
        "436": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  436"
        },
        "437": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 437"
        },
        "438": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 438"
        },
        "439": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 439"
        },
        "440": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 440"
        },
        "441": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*), Xiaoqing-6B (*), OncoGPT-7B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br><br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $31196. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). Fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.  441"
        },
        "442": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The price of renting GPUs with 192GB of memory using a cloud service is $15/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 442"
        },
        "443": {
            "answer": "The LLMs we recommend you use are: Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 443"
        },
        "444": {
            "answer": "The LLMs we recommend you use are: Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 444"
        },
        "447": {
            "answer": "Sorry, no matching LLMs were found. 447"
        },
        "448": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.  448"
        },
        "449": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 449"
        },
        "450": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.  450"
        },
        "451": {
            "answer": "Sorry, no matching LLMs were found. 451"
        },
        "452": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 452"
        },
        "453": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. 453"
        },
        "454": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.  454"
        },
        "455": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  455"
        },
        "456": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GPT-4o (*), MMedIns-Llama 3-8B (*), Google Bard, Claude 3.5 Sonnet, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 456"
        },
        "457": {
            "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Med-Flamingo-7B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 457"
        },
        "458": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*), MMedIns-Llama 3-8B (*), Claude 3.5 Sonnet (*), GPT-4o (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens. 458"
        },
        "459": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 459"
        },
        "460": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GPT-4o (*), MMedIns-Llama 3-8B (*), Google Bard, Claude 3.5 Sonnet, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 460"
        },
        "461": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $72000. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>. 461"
        },
        "462": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*), Claude 3.5 Sonnet (*), GPT-4o (*), Claude 3 Opus (*), Claude 3 Haiku (*), GPT-4o1 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The price of renting 4 this type of GPU using cloud services is $25/1h. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Claude 3 Opus: the input price is $0.015/1k tokens and the output price is $0.075/1k tokens.<br><br>Claude 3 Haiku: the input price is $0.00025/1k tokens and the output price is $0.00125/1k tokens.<br><br>GPT-4o1: the input price is $0.015/1k tokens and the output price is $0.06/1k tokens.  462"
        },
        "463": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  463"
        },
        "464": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 464"
        },
        "465": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 465"
        },
        "466": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 466"
        },
        "467": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 467"
        },
        "468": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 468"
        },
        "469": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 469"
        },
        "470": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank' class='custom-link'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 470"
        },
        "471": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 471"
        },
        "472": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), MMedIns-Llama 3-8B (*), GPT-4o (*), Google Bard, Claude 3.5 Sonnet, LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 472"
        },
        "473": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*), Xiaoqing-6B (*), OncoGPT-7B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br><br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $31196. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). Fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 473"
        },
        "474": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*), Xiaoqing-6B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*), Claude 3.5 Sonnet (*), GPT-4o (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br><br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The price of renting GPUs with 192GB of memory using a cloud service is $15/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>Claude 3.5 Sonnet: the input price is $0.003/1k tokens and the output price is $0.015/1k tokens.<br><br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens. 474"
        },
        "475": {
            "answer": "The LLMs we recommend you use are: Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  475"
        },
        "476": {
            "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), GPT-4o (*), Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br> <br>GPT-4o: the input price is $0.0025/1k tokens and the output price is $0.01/1k tokens.<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 476"
        },
        "481": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598. 481"
        },
        "482": {
            "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC, Clinical Camel-70B. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.  482"
        },
        "485": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPU is 600W and the total price is $15598.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.485"
        },
        "486": {
            "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M, Clinical Camel-70B, Vicuna-13B. Here are the required resources:<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>Clinical Camel-70B: fine-tuning requires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.  486"
        },
        "487": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  487"
        },
        "488": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 488"
        },
        "489": {
            "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Med-Flamingo-7B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 489"
        },
        "490": {
            "answer": "The LLMs we recommend you use are: Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 490"
        },
        "491": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  491"
        },
        "492": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 492"
        },
        "493": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 38400W and the total price is $2304000. Fine-tune reuqires 1 H100 GPU. The total thermal design power of the GPU is 300W and the total price is $45000. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $72000. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>. 493"
        },
        "494": {
            "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), MedFound-176B (*), MMedIns-Llama 3-8B (*), Vicuna 1.5-7B (*), RetinalGPT (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank' class='custom-link'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model are provided, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA RTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>MedFound-176B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 128 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $800/1h. Fine-tune reuqires 1 H100 GPU. The price of renting 1 this type of GPU using cloud services is $11/1h. It can be accessed via link <a href='https://huggingface.co/medicalai/MedFound-176B' target='_blank' class='custom-link'>MedFound GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>Vicuna 1.5-7B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 8 this type of GPU using cloud services is $8.1/1h.<br><br>RetinalGPT: fine-tuning requires 4 NVIDIA TESLA A100-80GB GPUs. The price of renting 4 this type of GPU using cloud services is $25/1h. It can be accessed via link <a href='https://github.com/Retinal-Research/RetinalGPT' target='_blank' class='custom-link'>RetinalGPT GitHub</a>. 494"
        },
        "495": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  495"
        },
        "496": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  496"
        },
        "497": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 497"
        },
        "498": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>. 498"
        },
        "499": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  499"
        },
        "500": {
            "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  500"
        },
        "501": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/cinquin/ChIP-GPT-llm' target='_blank' class='custom-link'>ChIP-GPT GitHub</a>. 501"
        },
        "502": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*), ChIP-GPT-33B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank' class='custom-link'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank' class='custom-link'>PhenoGPT GitHub</a>.<br><br>ChIP-GPT-33B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>. 502"
        },
        "503": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The total thermal design power of the GPU is 295W and the total price is $4300.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.  503"
        },
        "504": {
            "answer": "The LLMs we recommend you use are: MMedIns-Llama 3-8B (*), LLaMA-7B, LLaMA-70B, ChatDoctor-7B, LLaMA2, Perplexity.ai, LLaMA3,  MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2. Here are the required resources:<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br>LLaMA2: the exact model size is not mentioned in the papers and is assumed here to be LLaMA2-7B. Fine-tuning requires 1 NVIDIA Quadro RTX 8000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>For Perplexity.ai, LLaMA3, MEDITRON, Mistral, InternLM 2, Qwen 2, Baichuan 2, Med42-v2, sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. 504"
        },
        "505": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*), Xiaoqing-6B (*), OncoGPT-7B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $144000. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>OphGLM-6.2B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank' class='custom-link'>OphGLM GitHub</a>.<br><br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The total thermal design power of the GPU is 450W and the total price is $1599. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br><br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPU is 300W and the total price is $18000. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 1200W and the total price is $31196. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). Fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000. Inference requires 2 NVIDIA A40-48GB GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>. 505"
        },
        "506": {
            "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), Xiaoqing-6B (*), OncoGPT-7B (*), PeFoMed-7B (*), MedVINT (*), M3D-LaMed (*), SlideChat (*), MMed-Llama 3-8B (*), MMedIns-Llama 3-8B (*), HuatuoGPT-Vision-34B (*), HuatuoGPT-o1-8B (*), HuatuoGPT-o1-70B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. <br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank' class='custom-link'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank' class='custom-link'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank' class='custom-link'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank' class='custom-link'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank' class='custom-link'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank' class='custom-link'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank' class='custom-link'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank' class='custom-link'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank' class='custom-link'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h.<br>Xiaoqing-6B: inference requires 1 NVIDIA RTX 4090-32GB GPU. The price of renting a GPU with 32GB of memory using a cloud service is $4.96/1h. It can be accessed via link <a href='https://qa.glaucoma-assistant.com//qa' target='_blank' class='custom-link'>Xiaoqing GitHub</a>.<br>OncoGPT-7B: fine-tuning requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h. It can be accessed via link <a href='https://github.com/OncoGPT1' target='_blank' class='custom-link'>OncoGPT1 GitHub</a>.<br><br>PeFoMed-7B: fine-tuning requires 4 NVIDIA A40-48GB GPUs. The price of renting GPUs with 192GB of memory using a cloud service is $15/1h. It can be accessed via link <a href='https://github.com/jinlHe/PeFoMed' target='_blank' class='custom-link'>PeFoMed GitHub</a>.<br><br>MedVINT: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. <br><br>M3D-LaMed: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://github.com/BAAI-DCAI/M3D' target='_blank' class='custom-link'>M3D GitHub</a>.<br><br>SlideChat: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available. It can be accessed via link <a https://uni-medical.github.io/SlideChat.github.io' target='_blank' class='custom-link'>SlideChat GitHub</a>.<br><br>MMed-Llama 3-8B: Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href=' https://huggingface.co/Henrychur/MMed-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.<br><br>HuatuoGPT-Vision-34B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (33B). The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>HuatuoGPT-o1-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.<br><br>HuatuoGPT-o1-70B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h. Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h. Inference requires 2 NVIDIA A40-48GB GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h. It can be accessed via link <a href='https://github.com/FreedomIntelligence/HuatuoGPT-o1' target='_blank' class='custom-link'>HuatuoGPTo1 GitHub</a>.  506"
        },
        "507": {
            "answer": "The LLMs we recommend you use are: Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>. 507"
        },
        "508": {
            "answer": "The LLMs we recommend you use are: Galactica (*), MMedIns-Llama 3-8B (*). Here are the required resources:<br><br>Galactica: sorry, there is no mention of the exact size of the model in the papers, so specific information is not available.<br><br>MMedIns-Llama 3-8B: no specific resource requirements for this model are provided, refer to resources for LLMs of similar size (8B). Pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. It can be accessed via link <a href='https://huggingface.co/Henrychur/MMedS-Llama-3-8B' target='_blank' class='custom-link'>MMedSLlama3 GitHub</a>.  508"
        }
    };
    const descriptions = {
        "textual data": "It refers to data presented in textual form, including medical records, radiology reports, patient histories, and other medically relevant textual information. Tabular data can also be used as textual data after being converted into textual form, such as a patient's laboratory indicators. However, data such as medical images, electrocardiograms, etc. are not textual data.",
        "perform tasks related to disease diagnosis": "It refers to the ability to perform at least one relevant task, including generating diagnostic conclusions based on patient descriptions, examination reports, clinical records or medical images (if non-textual input), disease classification tasks, etc.",
        "extract medical information":"It refers to the ability to perform at least one similar task, such as summarizing the impression portion of a radiology report, summarizing questions posed by the patient related to the radiology report, etc.",
        "locally":"It refers to the way the LLMs is deployed and run in the local environment. It allows for better control and management of model operations, protects the privacy and security of patient data, and reduces reliance on external networks. Local environment refers to a specific computing environment that is operated and developed on a personal computer or specific device. It can be a server, desktop computer, laptop or mobile device within a healthcare organization, etc.",
        "in the cloud":"It refers to the deployment of LLMs in a cloud computing environment. Cloud computing is based on network providing computing resources and services through remote servers.  By deploying LLMs in the cloud, medical professionals can take full advantage of the high-performance computing resources provided by cloud computing. Training, reasoning, and management of models in the cloud can greatly reduce the burden on local devices and can flexibly adjust the scale of computing resources according to demand. Cloud computing also provides advanced data security and privacy protections that can ensure the safety and reliability of medical data. Accessing commercial LLMs like ChatGPT through an api or website also falls under the category of cloud deployment, but data privacy and security are not guaranteed.",
        "answer medical questions":"medical questions includes multiple-choice and open-ended questions (and may also include visual questions, i.e., where there are medical images in the input) on tasks related to the disease diagnosis and treatment planning. Open questions are questions that require a free-form text answer. These questions usually require more in-depth thinking and personalized answers rather than choosing from a limited number of options. For example, these questions may involve descriptions of specific symptoms of the patient, detailed documentation of past medical history, preferences or limitations of specific treatment options, etc., information that is not fully accessible from traditional multiple-choice questions.",
        "generate text related to medical decision making":"It refers to the ability to perform at least one similar task, including the generation of patient treatment plans, improved clinical decision support recommendations, etc."
    };

    let currentNode = "0"; // Starting node
    let questionHistory = []; // Keeps track of answered questions

    // Function to display a question based on the node
    function displayQuestion(node, questionIndex) {
        const questionContainer = document.getElementById('questionContainer');
        // Clear questions beyond this index
        questionContainer.innerHTML = '';

        // Display history
        questionHistory.slice(0, questionIndex).forEach(q => appendQuestion(q.node, q.choice, q.number));

        // Display the current question
        appendQuestion(node, null, questionIndex + 1);
    }

    function appendQuestion(node, selectedChoice, questionNumber) {
        const questionContainer = document.getElementById('questionContainer');

        if (data[node] && data[node].question) {
            const questionDiv = document.createElement('div');
            questionDiv.classList.add('question');

            // Display fixed question number
            const questionNumberElem = document.createElement('p');
            questionNumberElem.classList.add('questionNumber');
            questionNumberElem.innerText = `Question ${questionNumber}:`;
            questionDiv.appendChild(questionNumberElem);

            // Display question text (with clickable keywords)
            const questionText = document.createElement('p');
            questionText.innerHTML = data[node].question; // Allows inner HTML to handle <span> tags
            questionDiv.appendChild(questionText);

            // Create Yes button
            const yesButton = document.createElement('button');
            yesButton.innerText = 'Yes';
            yesButton.classList.toggle('selected', selectedChoice === 'yes');
            yesButton.onclick = function () {
                updateHistory(node, 'yes', questionNumber);
                currentNode = data[node].yes;
                displayQuestion(currentNode, questionNumber);
            };
            questionDiv.appendChild(yesButton);

            // Create No button
            const noButton = document.createElement('button');
            noButton.innerText = 'No';
            noButton.classList.toggle('selected', selectedChoice === 'no');
            noButton.onclick = function () {
                updateHistory(node, 'no', questionNumber);
                currentNode = data[node].no;
                displayQuestion(currentNode, questionNumber);
            };
            questionDiv.appendChild(noButton);

            // Append the question block to the container
            questionContainer.appendChild(questionDiv);

            // Attach event listeners to keywords
            const highlightElements = questionDiv.querySelectorAll('.highlight');
            highlightElements.forEach(function (element) {
                element.addEventListener('click', function () {
                    const keyword = element.getAttribute('data-keyword');
                    showDescription(keyword);
                });
            });

        } else if (data[node] && data[node].answer) {
            // Create a div for the final answer
            const answerDiv = document.createElement('div');
            answerDiv.classList.add('answer');

            const answerText = document.createElement('p');
            answerText.innerHTML = data[node].answer;  // Allow HTML content for line breaks and links
            answerDiv.appendChild(answerText);

            // Append the answer to the container
            questionContainer.appendChild(answerDiv);
        } else {
            // Handle if no more questions or no data found
            const noMoreQuestions = document.createElement('p');
            noMoreQuestions.innerText = "No more questions available.";
            questionContainer.appendChild(noMoreQuestions);
        }
    }

    function showDescription(keyword) {
        const descriptionText = descriptions[keyword];
        if (descriptionText) {
            document.getElementById('descriptionText').innerText = descriptionText;
            document.getElementById('descriptionContainer').style.display = 'block';
        }
    }

    document.getElementById('closeButton').addEventListener('click', function () {
        document.getElementById('descriptionContainer').style.display = 'none';
    });

    function updateHistory(node, choice, questionNumber) {
        // Check if we are revisiting a question and modify history accordingly
        const historyIndex = questionHistory.findIndex(q => q.number === questionNumber);
        if (historyIndex !== -1) {
            questionHistory = questionHistory.slice(0, historyIndex); // Remove subsequent questions
        }

        // Add current question to history
        questionHistory.push({ node, choice, number: questionNumber });
    }

    // Start the first question
    displayQuestion(currentNode, 0);
});</script>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="assets/js/template.js"></script>
</body>
</html>
