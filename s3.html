<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Questionnaire</title>
    <style>
        .questionNumber {
            font-weight: bold;
        }
        .selected {
            color: red;
        }
    </style>
</head>
<body>
    <!-- Instructions -->
    <div class="instruction">
        Next, answer the following questions to find the most suitable LLM for your use case:
    </div>
    <div class="buttonContainer">
        <button onclick="location.href='./'">Return to the initial screen </button>
    </div>

    <div id="questionContainer"></div>

    <script>
        document.addEventListener('DOMContentLoaded', function() {
            const data = {
                "0": {
                    "question": "Does your input include only textual data?",
                    "yes": "1",
                    "no": "2"
                },
                "1": {
                    "question": "Does your output include only textual data?",
                    "yes": "3",
                    "no": "4"
                },
                "2": {
                    "question": "Does your output include only textual data?",
                    "yes": "5",
                    "no": "6"
                },
                "3": {
                    "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
                    "yes": "7",
                    "no": "8"
                },
                "4": {
                    "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
                    "yes": "9",
                    "no": "10"
                },
                "5": {
                    "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
                    "yes": "11",
                    "no": "12"
                },
                "6": {
                    "question": "Do you agree that your data may be shared with third parties, published, or made generally available?",
                    "yes": "13",
                    "no": "14"
                },
                "7": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 7",
                    "yes": "15",
                    "no": "16"
                },
                "8": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 8",
                    "yes": "17",
                    "no": "18"
                },
                "9": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 9",
                    "yes": "19",
                    "no": "20"
                },
                "10": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 10",
                    "yes": "21",
                    "no": "22"
                },
                "11": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 11",
                    "yes": "23",
                    "no": "24"
                },
                "12": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 12",
                    "yes": "25",
                    "no": "26"
                },
                "13": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 13",
                    "yes": "27",
                    "no": "28"
                },
                "14": {
                    "question": "Do you need LLM to be able to generate diagnostic conclusions? 14",
                    "yes": "29",
                    "no": "30"
                },
                "15": {
                    "question": "Do you need LLM to be able to extract medical information? 15",
                    "yes": "31",
                    "no": "32"
                },
                "16": {
                    "question": "Do you need LLM to be able to extract medical information? 16",
                    "yes": "33",
                    "no": "34"
                },
                "17": {
                    "question": "Do you need LLM to be able to extract medical information? 17",
                    "yes": "35",
                    "no": "36"
                },
                "18": {
                    "question": "Do you need LLM to be able to extract medical information? 18",
                    "yes": "37",
                    "no": "38"
                },
                "19": {
                    "question": "Do you need LLM to be able to extract medical information? 19",
                    "yes": "39",
                    "no": "40"
                },
                "20": {
                    "question": "Do you need LLM to be able to extract medical information? 20",
                    "yes": "41",
                    "no": "42"
                },
                "21": {
                    "question": "Do you need LLM to be able to extract medical information? 21",
                    "yes": "43",
                    "no": "44"
                },
                "22": {
                    "question": "Do you need LLM to be able to extract medical information? 22",
                    "yes": "45",
                    "no": "46"
                },
                "23": {
                    "question": "Do you need LLM to be able to extract medical information? 23",
                    "yes": "47",
                    "no": "48"
                },
                "24": {
                    "question": "Do you need LLM to be able to extract medical information? 24",
                    "yes": "49",
                    "no": "50"
                },
                "25": {
                    "question": "Do you need LLM to be able to extract medical information? 25",
                    "yes": "51",
                    "no": "52"
                },
                "26": {
                    "question": "Do you need LLM to be able to extract medical information? 26",
                    "yes": "53",
                    "no": "54"
                },
                "27": {
                    "question": "Do you need LLM to be able to extract medical information? 27",
                    "yes": "55",
                    "no": "56"
                },
                "28": {
                    "question": "Do you need LLM to be able to extract medical information? 28",
                    "yes": "57",
                    "no": "58"
                },
                "29": {
                    "question": "Do you need LLM to be able to extract medical information? 29",
                    "yes": "59",
                    "no": "60"
                },
                "30": {
                    "question": "Do you need LLM to be able to extract medical information? 30",
                    "yes": "61",
                    "no": "62"
                },
                "31": {
                    "question": "Do you need LLM to be able to answer medical questions? 31",
                    "yes": "63",
                    "no": "64"
                },
                "32": {
                    "question": "Do you need LLM to be able to answer medical questions? 32",
                    "yes": "65",
                    "no": "66"
                },
                "33": {
                    "question": "Do you need LLM to be able to answer medical questions? 33",
                    "yes": "67",
                    "no": "68"
                },
                "34": {
                    "question": "Do you need LLM to be able to answer medical questions? 34",
                    "yes": "69",
                    "no": "70"
                },
                "35": {
                    "question": "Do you need LLM to be able to answer medical questions? 35",
                    "yes": "71",
                    "no": "72"
                },
                "36": {
                    "question": "Do you need LLM to be able to answer medical questions? 36",
                    "yes": "73",
                    "no": "74"
                },
                "37": {
                    "question": "Do you need LLM to be able to answer medical questions? 37",
                    "yes": "75",
                    "no": "76"
                },
                "38": {
                    "question": "Do you need LLM to be able to answer medical questions? 38",
                    "yes": "77",
                    "no": "78"
                },
                "39": {
                    "question": "Do you need LLM to be able to answer medical questions? 39",
                    "yes": "79",
                    "no": "80"
                },
                "40": {
                    "question": "Do you need LLM to be able to answer medical questions? 40",
                    "yes": "81",
                    "no": "82"
                },
                "41": {
                    "question": "Do you need LLM to be able to answer medical questions? 41",
                    "yes": "83",
                    "no": "84"
                },
                "42": {
                    "question": "Do you need LLM to be able to answer medical questions? 42",
                    "yes": "85",
                    "no": "86"
                },
                "43": {
                    "question": "Do you need LLM to be able to answer medical questions? 43",
                    "yes": "87",
                    "no": "88"
                },
                "44": {
                    "question": "Do you need LLM to be able to answer medical questions? 44",
                    "yes": "89",
                    "no": "90"
                },
                "45": {
                    "question": "Do you need LLM to be able to answer medical questions? 45",
                    "yes": "91",
                    "no": "92"
                },
                "46": {
                    "question": "Do you need LLM to be able to answer medical questions? 46",
                    "yes": "93",
                    "no": "94"
                },
                "47": {
                    "question": "Do you need LLM to be able to answer medical questions? 47",
                    "yes": "95",
                    "no": "96"
                },
                "48": {
                    "question": "Do you need LLM to be able to answer medical questions? 48",
                    "yes": "97",
                    "no": "98"
                },
                "49": {
                    "question": "Do you need LLM to be able to answer medical questions? 49",
                    "yes": "99",
                    "no": "100"
                },
                "50": {
                    "question": "Do you need LLM to be able to answer medical questions? 50",
                    "yes": "101",
                    "no": "102"
                },
                "51": {
                    "question": "Do you need LLM to be able to answer medical questions? 51",
                    "yes": "103",
                    "no": "104"
                },
                "52": {
                    "question": "Do you need LLM to be able to answer medical questions? 52",
                    "yes": "105",
                    "no": "106"
                },
                "53": {
                    "question": "Do you need LLM to be able to answer medical questions? 53",
                    "yes": "107",
                    "no": "108"
                },
                "54": {
                    "question": "Do you need LLM to be able to answer medical questions? 54",
                    "yes": "109",
                    "no": "110"
                },
                "55": {
                    "question": "Do you need LLM to be able to answer medical questions? 55",
                    "yes": "111",
                    "no": "112"
                },
                "56": {
                    "question": "Do you need LLM to be able to answer medical questions? 56",
                    "yes": "113",
                    "no": "114"
                },
                "57": {
                    "question": "Do you need LLM to be able to answer medical questions? 57",
                    "yes": "115",
                    "no": "116"
                },
                "58": {
                    "question": "Do you need LLM to be able to answer medical questions? 58",
                    "yes": "117",
                    "no": "118"
                },
                "59": {
                    "question": "Do you need LLM to be able to answer medical questions? 59",
                    "yes": "119",
                    "no": "120"
                },
                "60": {
                    "question": "Do you need LLM to be able to answer medical questions? 60",
                    "yes": "121",
                    "no": "122"
                },
                "61": {
                    "question": "Do you need LLM to be able to answer medical questions? 61",
                    "yes": "123",
                    "no": "124"
                },
                "62": {
                    "question": "Do you need LLM to be able to answer medical questions? 62",
                    "yes": "125",
                    "no": "126"
                },
                "63": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 63",
                    "yes": "127",
                    "no": "128"
                },
                "64": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 64",
                    "yes": "129",
                    "no": "130"
                },
                "65": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 65",
                    "yes": "131",
                    "no": "132"
                },
                "66": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 66",
                    "yes": "133",
                    "no": "134"
                },
                "67": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 67",
                    "yes": "135",
                    "no": "136"
                },
                "68": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 68",
                    "yes": "137",
                    "no": "138"
                },
                "69": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 69",
                    "yes": "139",
                    "no": "140"
                },
                "70": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 70",
                    "yes": "141",
                    "no": "142"
                },
                "71": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 71",
                    "yes": "143",
                    "no": "144"
                },
                "72": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 72",
                    "yes": "145",
                    "no": "146"
                },
                "73": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 73",
                    "yes": "147",
                    "no": "148"
                },
                "74": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 74",
                    "yes": "149",
                    "no": "150"
                },
                "75": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 75",
                    "yes": "151",
                    "no": "152"
                },
                "76": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 76",
                    "yes": "153",
                    "no": "154"
                },
                "77": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 77",
                    "yes": "155",
                    "no": "156"
                },
                "78": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 78",
                    "yes": "157",
                    "no": "158"
                },
                "79": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 79",
                    "yes": "159",
                    "no": "160"
                },
                "80": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 80",
                    "yes": "161",
                    "no": "162"
                },
                "81": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 81",
                    "yes": "163",
                    "no": "164"
                },
                "82": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 82",
                    "yes": "165",
                    "no": "166"
                },
                "83": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 83",
                    "yes": "167",
                    "no": "168"
                },
                "84": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 84",
                    "yes": "169",
                    "no": "170"
                },
                "85": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 85",
                    "yes": "171",
                    "no": "172"
                },
                "86": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 86",
                    "yes": "173",
                    "no": "174"
                },
                "87": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 87",
                    "yes": "175",
                    "no": "176"
                },
                "88": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 88",
                    "yes": "177",
                    "no": "178"
                },
                "89": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 89",
                    "yes": "179",
                    "no": "180"
                },
                "90": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 90",
                    "yes": "181",
                    "no": "182"
                },
                "91": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 91",
                    "yes": "183",
                    "no": "184"
                },
                "92": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 92",
                    "yes": "185",
                    "no": "186"
                },
                "93": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 93",
                    "yes": "187",
                    "no": "188"
                },
                "94": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 94",
                    "yes": "189",
                    "no": "190"
                },
                "95": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 95",
                    "yes": "191",
                    "no": "192"
                },
                "96": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 96",
                    "yes": "193",
                    "no": "194"
                },
                "97": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 97",
                    "yes": "195",
                    "no": "196"
                },
                "98": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 98",
                    "yes": "197",
                    "no": "198"
                },
                "99": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 99",
                    "yes": "199",
                    "no": "200"
                },
                "100": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 100",
                    "yes": "201",
                    "no": "202"
                },
                "101": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 101",
                    "yes": "203",
                    "no": "204"
                },
                "102": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 102",
                    "yes": "205",
                    "no": "206"
                },
                "103": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 103",
                    "yes": "207",
                    "no": "208"
                },
                "104": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 104",
                    "yes": "209",
                    "no": "210"
                },
                "105": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 105",
                    "yes": "211",
                    "no": "212"
                },
                "106": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 106",
                    "yes": "213",
                    "no": "214"
                },
                "107": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 107",
                    "yes": "215",
                    "no": "216"
                },
                "108": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 108",
                    "yes": "217",
                    "no": "218"
                },
                "109": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 109",
                    "yes": "219",
                    "no": "220"
                },
                "110": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 110",
                    "yes": "221",
                    "no": "222"
                },
                "111": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 111",
                    "yes": "223",
                    "no": "224"
                },
                "112": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 112",
                    "yes": "225",
                    "no": "226"
                },
                "113": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 113",
                    "yes": "227",
                    "no": "228"
                },
                "114": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 114",
                    "yes": "229",
                    "no": "230"
                },
                "115": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 115",
                    "yes": "231",
                    "no": "232"
                },
                "116": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 116",
                    "yes": "233",
                    "no": "234"
                },
                "117": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 117",
                    "yes": "235",
                    "no": "236"
                },
                "118": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 118",
                    "yes": "237",
                    "no": "238"
                },
                "119": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 119",
                    "yes": "239",
                    "no": "240"
                },
                "120": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 120",
                    "yes": "241",
                    "no": "242"
                },
                "121": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 121",
                    "yes": "243",
                    "no": "244"
                },
                "122": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 122",
                    "yes": "245",
                    "no": "246"
                },
                "123": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 123",
                    "yes": "247",
                    "no": "248"
                },
                "124": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 124",
                    "yes": "249",
                    "no": "250"
                },
                "125": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 125",
                    "yes": "251",
                    "no": "252"
                },
                "126": {
                    "question": "Do you need LLM to be able to generate text related to medical decision making? 126",
                    "yes": "253",
                    "no": "254"
                },
                "127": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 127",
                    "yes": "255",
                    "no": "256"
                },
                "128": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 128",
                    "yes": "257",
                    "no": "258"
                },
                "129": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 129",
                    "yes": "259",
                    "no": "260"
                },
                "130": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 130",
                    "yes": "261",
                    "no": "262"
                },
                "131": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 131",
                    "yes": "263",
                    "no": "264"
                },
                "132": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 132",
                    "yes": "265",
                    "no": "266"
                },
                "133": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 133",
                    "yes": "267",
                    "no": "268"
                },
                "134": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 134",
                    "yes": "269",
                    "no": "270"
                },
                "135": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 135",
                    "yes": "271",
                    "no": "272"
                },
                "136": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 136",
                    "yes": "273",
                    "no": "274"
                },
                "137": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 137",
                    "yes": "275",
                    "no": "276"
                },
                "138": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 138",
                    "yes": "277",
                    "no": "278"
                },
                "139": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 139",
                    "yes": "279",
                    "no": "280"
                },
                "140": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 140",
                    "yes": "281",
                    "no": "282"
                },
                "141": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 141",
                    "yes": "283",
                    "no": "284"
                },
                "142": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 142"
                },
                "143": {
                    "answer": "Sorry, no matching LLMs were found. 143"
                },
                "144": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 144",
                    "yes": "289",
                    "no": "290"
                },
                "145": {
                    "answer": "Sorry, no matching LLMs were found. 145"
                },
                "146": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 146",
                    "yes": "293",
                    "no": "294"
                },
                "147": {
                    "answer": "Sorry, no matching LLMs were found. 147"
                },
                "148": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 148",
                    "yes": "297",
                    "no": "298"
                },
                "149": {
                    "answer": "Sorry, no matching LLMs were found. 149"
                },
                "150": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 150",
                    "yes": "301",
                    "no": "302"
                },
                "151": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 151",
                    "yes": "303",
                    "no": "304"
                },
                "152": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 152",
                    "yes": "305",
                    "no": "306"
                },
                "153": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 153",
                    "yes": "307",
                    "no": "308"
                },
                "154": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 154",
                    "yes": "309",
                    "no": "310"
                },
                "155": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 155",
                    "yes": "311",
                    "no": "312"
                },
                "156": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 156",
                    "yes": "313",
                    "no": "314"
                },
                "157": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 157",
                    "yes": "315",
                    "no": "316"
                },
                "158": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 158"
                },
                "159": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 159",
                    "yes": "319",
                    "no": "320"
                },
                "160": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 160",
                    "yes": "321",
                    "no": "322"
                },
                "161": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 161",
                    "yes": "323",
                    "no": "324"
                },
                "162": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 162",
                    "yes": "325",
                    "no": "326"
                },
                "163": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 163",
                    "yes": "327",
                    "no": "328"
                },
                "164": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 164",
                    "yes": "329",
                    "no": "330"
                },
                "165": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 165",
                    "yes": "331",
                    "no": "332"
                },
                "166": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 166",
                    "yes": "333",
                    "no": "334"
                },
                "167": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 167",
                    "yes": "335",
                    "no": "336"
                },
                "168": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 168",
                    "yes": "337",
                    "no": "338"
                },
                "169": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 169",
                    "yes": "339",
                    "no": "340"
                },
                "170": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 170",
                    "yes": "341",
                    "no": "342"
                },
                "171": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 171",
                    "yes": "343",
                    "no": "344"
                },
                "172": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 172",
                    "yes": "345",
                    "no": "346"
                },
                "173": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 173",
                    "yes": "347",
                    "no": "348"
                },
                "174": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 174"
                },
                "175": {
                    "answer": "Sorry, no matching LLMs were found. 175"
                },
                "176": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 176",
                    "yes": "353",
                    "no": "354"
                },
                "177": {
                    "answer": "Sorry, no matching LLMs were found. 177"
                },
                "178": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 178",
                    "yes": "357",
                    "no": "358"
                },
                "179": {
                    "answer": "Sorry, no matching LLMs were found. 179"
                },
                "180": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 180",
                    "yes": "361",
                    "no": "362"
                },
                "181": {
                    "answer": "Sorry, no matching LLMs were found. 181"
                },
                "182": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 182",
                    "yes": "365",
                    "no": "366"
                },
                "183": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 183",
                    "yes": "367",
                    "no": "368"
                },
                "184": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 184",
                    "yes": "369",
                    "no": "370"
                },
                "185": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 185",
                    "yes": "371",
                    "no": "372"
                },
                "186": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 186",
                    "yes": "373",
                    "no": "374"
                },
                "187": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 187",
                    "yes": "375",
                    "no": "376"
                },
                "188": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 188",
                    "yes": "377",
                    "no": "378"
                },
                "189": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 189",
                    "yes": "379",
                    "no": "380"
                },
                "190": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 190"
                },
                "191": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 191",
                    "yes": "383",
                    "no": "384"
                },
                "192": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 192",
                    "yes": "385",
                    "no": "386"
                },
                "193": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 193",
                    "yes": "387",
                    "no": "388"
                },
                "194": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 194",
                    "yes": "389",
                    "no": "390"
                },
                "195": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 195",
                    "yes": "391",
                    "no": "392"
                },
                "196": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 196",
                    "yes": "393",
                    "no": "394"
                },
                "197": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 197",
                    "yes": "395",
                    "no": "396"
                },
                "198": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 198",
                    "yes": "397",
                    "no": "398"
                },
                "199": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 199",
                    "yes": "399",
                    "no": "400"
                },
                "200": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 200",
                    "yes": "401",
                    "no": "402"
                },
                "201": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 201",
                    "yes": "403",
                    "no": "404"
                },
                "202": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 202",
                    "yes": "405",
                    "no": "406"
                },
                "203": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 203",
                    "yes": "407",
                    "no": "408"
                },
                "204": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 204",
                    "yes": "409",
                    "no": "410"
                },
                "205": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 205",
                    "yes": "411",
                    "no": "412"
                },
                "206": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 206"
                },
                "207": {
                    "answer": "Sorry, no matching LLMs were found. 207"
                },
                "208": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 208",
                    "yes": "417",
                    "no": "418"
                },
                "209": {
                    "answer": "Sorry, no matching LLMs were found. 209"
                },
                "210": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 210",
                    "yes": "421",
                    "no": "422"
                },
                "211": {
                    "answer": "Sorry, no matching LLMs were found. 211"
                },
                "212": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 212",
                    "yes": "425",
                    "no": "426"
                },
                "213": {
                    "answer": "Sorry, no matching LLMs were found. 213"
                },
                "214": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 214",
                    "yes": "429",
                    "no": "430"
                },
                "215": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 215",
                    "yes": "431",
                    "no": "432"
                },
                "216": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 216",
                    "yes": "433",
                    "no": "434"
                },
                "217": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 217",
                    "yes": "435",
                    "no": "436"
                },
                "218": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 218",
                    "yes": "437",
                    "no": "438"
                },
                "219": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 219",
                    "yes": "439",
                    "no": "440"
                },
                "220": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 220",
                    "yes": "441",
                    "no": "442"
                },
                "221": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 221",
                    "yes": "443",
                    "no": "444"
                },
                "222": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 222"
                },
                "223": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 223",
                    "yes": "447",
                    "no": "448"
                },
                "224": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 224",
                    "yes": "449",
                    "no": "450"
                },
                "225": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 225",
                    "yes": "451",
                    "no": "452"
                },
                "226": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 226",
                    "yes": "453",
                    "no": "454"
                },
                "227": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 227",
                    "yes": "455",
                    "no": "456"
                },
                "228": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 228",
                    "yes": "457",
                    "no": "458"
                },
                "229": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 229",
                    "yes": "459",
                    "no": "460"
                },
                "230": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 230",
                    "yes": "461",
                    "no": "462"
                },
                "231": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 231",
                    "yes": "463",
                    "no": "464"
                },
                "232": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 232",
                    "yes": "465",
                    "no": "466"
                },
                "233": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 233",
                    "yes": "467",
                    "no": "468"
                },
                "234": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 234",
                    "yes": "469",
                    "no": "470"
                },
                "235": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 235",
                    "yes": "471",
                    "no": "472"
                },
                "236": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 236",
                    "yes": "473",
                    "no": "474"
                },
                "237": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 237",
                    "yes": "475",
                    "no": "476"
                },
                "238": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 238"
                },
                "239": {
                    "answer": "Sorry, no matching LLMs were found. 239"
                },
                "240": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 240",
                    "yes": "481",
                    "no": "482"
                },
                "241": {
                    "answer": "Sorry, no matching LLMs were found. 241"
                },
                "242": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 242",
                    "yes": "485",
                    "no": "486"
                },
                "243": {
                    "answer": "Sorry, no matching LLMs were found. 243"
                },
                "244": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 244",
                    "yes": "489",
                    "no": "490"
                },
                "245": {
                    "answer": "Sorry, no matching LLMs were found. 245"
                },
                "246": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 246",
                    "yes": "493",
                    "no": "494"
                },
                "247": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 247",
                    "yes": "495",
                    "no": "496"
                },
                "248": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 248",
                    "yes": "497",
                    "no": "498"
                },
                "249": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 249",
                    "yes": "499",
                    "no": "500"
                },
                "250": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 250",
                    "yes": "501",
                    "no": "502"
                },
                "251": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 251",
                    "yes": "503",
                    "no": "504"
                },
                "252": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 252",
                    "yes": "505",
                    "no": "506"
                },
                "253": {
                    "question": "Do you prefer to deploy LLM locally rather than in the cloud? 253",
                    "yes": "507",
                    "no": "508"
                },
                "254": {
                    "answer": "Sorry, there is not enough information to recommend LLM, please reselect the option. 254"
                },
                "255": {
                    "answer": "Sorry, no matching LLMs were found. 255"
                },
                "256": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 256"
                },
                "257": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 257"
                },
                "258": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), Google Bard, GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br> <br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 258"
                },
                "259": {
                    "answer": "Sorry, no matching LLMs were found. 259"
                },
                "260": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br>  260"
                },
                "261": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 261"
                },
                "262": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 262"
                },
                "263": {
                    "answer": "Sorry, no matching LLMs were found. 263"
                },
                "264": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br> 264"
                },
                "265": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br> 265"
                },
                "266": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br> 266"
                },
                "267": {
                    "answer": "Sorry, no matching LLMs were found. 267"
                },
                "268": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br>   268"
                },
                "269": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 269"
                },
                "270": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 270"
                },
                "271": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 271"
                },
                "272": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 272"
                },
                "273": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 273"
                },
                "274": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 274"
                },
                "275": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 275"
                },
                "276": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 276"
                },
                "277": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 277"
                },
                "278": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>.  278"
                },
                "279": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 279"
                },
                "280": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 280"
                },
                "281": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 281"
                },
                "282": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 282"
                },
                "283": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 283"
                },
                "284": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br> <br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 284"
                },
                "289": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 289"
                },
                "290": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 290"
                },
                "293": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 293"
                },
                "294": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 294"
                },
                "297": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 297"
                },
                "298": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 298"
                },
                "301": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 301"
                },
                "302": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.  302"
                },
                "303": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  303"
                },
                "304": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  304"
                },
                "305": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 305"
                },
                "306": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 306"
                },
                "307": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  307"
                },
                "308": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  308"
                },
                "309": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 309"
                },
                "310": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 310"
                },
                "311": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 311"
                },
                "312": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 312"
                },
                "313": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 313"
                },
                "314": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 314"
                },
                "315": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 315"
                },
                "316": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 316"
                },
                "319": {
                    "answer": "Sorry, no matching LLMs were found. 319"
                },
                "320": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 320"
                },
                "321": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 321"
                },
                "322": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), Google Bard, GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br> <br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 322"
                },
                "323": {
                    "answer": "Sorry, no matching LLMs were found. 323"
                },
                "324": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 324"
                },
                "325": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 325"
                },
                "326": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 326"
                },
                "327": {
                    "answer": "Sorry, no matching LLMs were found. 327"
                },
                "328": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 328"
                },
                "329": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 329"
                },
                "330": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 330"
                },
                "331": {
                    "answer": "Sorry, no matching LLMs were found. 331"
                },
                "332": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 332"
                },
                "333": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.  333"
                },
                "334": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 334"
                },
                "335": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 335"
                },
                "336": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 336"
                },
                "337": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 337"
                },
                "338": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 338"
                },
                "339": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 339"
                },
                "340": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 340"
                },
                "341": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 341"
                },
                "342": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 342"
                },
                "343": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 343"
                },
                "344": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 344"
                },
                "345": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 345"
                },
                "346": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 346"
                },
                "347": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 347"
                },
                "348": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br> <br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 348"
                },
                "353": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 353"
                },
                "354": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 354"
                },
                "357": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 357"
                },
                "358": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.  358"
                },
                "361": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 361"
                },
                "362": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 362"
                },
                "365": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 365"
                },
                "366": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 366"
                },
                "367": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  367"
                },
                "368": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  368"
                },
                "369": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 369"
                },
                "370": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 370"
                },
                "371": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  371"
                },
                "372": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  372"
                },
                "373": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 373"
                },
                "374": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 374"
                },
                "375": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 375"
                },
                "376": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 376"
                },
                "377": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 377"
                },
                "378": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>. 378"
                },
                "379": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.  379"
                },
                "380": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.  380"
                },
                "383": {
                    "answer": "Sorry, no matching LLMs were found. 383"
                },
                "384": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.  384"
                },
                "385": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 385"
                },
                "386": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 386"
                },
                "387": {
                    "answer": "Sorry, no matching LLMs were found. 387"
                },
                "388": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 388"
                },
                "389": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 389"
                },
                "390": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 390"
                },
                "391": {
                    "answer": "Sorry, no matching LLMs were found. 391"
                },
                "392": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 392"
                },
                "393": {
                    "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>Med-Flamingo-7B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 393"
                },
                "394": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 394"
                },
                "395": {
                    "answer": "Sorry, no matching LLMs were found. 395"
                },
                "396": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 396"
                },
                "397": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 397"
                },
                "398": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 398"
                },
                "399": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 399"
                },
                "400": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 400"
                },
                "401": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> 401"
                },
                "402": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 402"
                },
                "403": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 403"
                },
                "404": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 404"
                },
                "405": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 405"
                },
                "406": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 406"
                },
                "407": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 407"
                },
                "408": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 408"
                },
                "409": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 409"
                },
                "410": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 410"
                },
                "411": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 411"
                },
                "412": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br> <br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 412"
                },
                "417": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 417"
                },
                "418": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 418"
                },
                "421": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 421"
                },
                "422": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 422"
                },
                "425": {
                    "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 425"
                },
                "426": {
                    "answer": "The LLMs we recommend you use are: Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 426"
                },
                "429": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 429"
                },
                "430": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 430"
                },
                "431": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  431"
                },
                "432": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  432"
                },
                "433": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 433"
                },
                "434": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 434"
                },
                "435": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  435"
                },
                "436": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  436"
                },
                "437": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 437"
                },
                "438": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 438"
                },
                "439": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 439"
                },
                "440": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 440"
                },
                "441": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. 441"
                },
                "442": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h. 442"
                },
                "443": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 443"
                },
                "444": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 444"
                },
                "447": {
                    "answer": "Sorry, no matching LLMs were found. 447"
                },
                "448": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.  448"
                },
                "449": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 449"
                },
                "450": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.  450"
                },
                "451": {
                    "answer": "Sorry, no matching LLMs were found. 451"
                },
                "452": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens. 452"
                },
                "453": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 453"
                },
                "454": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.  454"
                },
                "455": {
                    "answer": "Sorry, no matching LLMs were found. 455"
                },
                "456": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 456"
                },
                "457": {
                    "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 457"
                },
                "458": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 458"
                },
                "459": {
                    "answer": "Sorry, no matching LLMs were found. 459"
                },
                "460": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens. 460"
                },
                "461": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 461"
                },
                "462": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard (*), GatorTron-345M (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*), OphGLM-6.2B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 462"
                },
                "463": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  463"
                },
                "464": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 464"
                },
                "465": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 465"
                },
                "466": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 466"
                },
                "467": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU. 467"
                },
                "468": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), LLaMA-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h. 468"
                },
                "469": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 469"
                },
                "470": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*), FraCGPT-4 (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>FraCGPT-4: can be accessed via link <a href='https://github.com/maxrusse/fracchat' target='_blank'>FraCGPT4 GitHub</a>.<br> <br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 470"
                },
                "471": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 471"
                },
                "472": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 472"
                },
                "473": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 473"
                },
                "474": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), GatorTron-8.9B (*), Bing Chat (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), GPT-4V (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*), OphGLM-6.2B (*). Here are the required resources:<br> <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Bing Chat: has been renamed to Copilot, the original version is not accessible, you can access the Copilot Advanced, averages $119 per month if paid annually.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is more than 36000W and the total price is more than $2160000.<br><br>Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>GPT-4V: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h.<br><br>OphGLM-6.2B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h. Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h. Inference requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h. It can be accessed via link <a href='https://github.com/ML-AILab/OphGLM' target='_blank'>OphGLM GitHub</a>. 474"
                },
                "475": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 475"
                },
                "476": {
                    "answer": "The LLMs we recommend you use are: GPT-4 (*), GPT-3.5 (*), Claude-instant-v1.0 (*), Google Bard, LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>GPT-4: the input price is $0.01/1k tokens and the output price is $0.03/1k tokens.<br><br>GPT-3.5: the input price is $0.0005/1k tokens and the output price is $0.0015/1k tokens.<br><br>Claude-instant-v1.0: the input price is $0.0008/1k tokens and the output price is $0.0024/1k tokens.<br> <br>Google Bard: has been renamed to Gemini, the original version is not accessible, you can access the latest Gemini 1.5 Pro.<br><br>The input price is $0.00125/1k tokens and the output price is $0.005/1k tokens.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 476"
                },
                "481": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 481"
                },
                "482": {
                    "answer": "The LLMs we recommend you use are: Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, BioBERT, BioMegatron, ClinicalBERT-110M, RadioLOGIC. Here are the required resources:<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 482"
                },
                "485": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15598.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600. 485"
                },
                "486": {
                    "answer": "The LLMs we recommend you use are: RadioLOGIC (*), Clinical-longformer-150M (*), GatorTron-345M, GatorTron-3.9B, GatorTron-8.9B, LLaMA2-70B, BERT, DeBERTa, RoBERTa, BioBERT, BioMegatron, ClinicalBERT-110M. Here are the required resources:<br>  <br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTron-3.9B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA2-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>BERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>DeBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>RoBERTa: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioMegatron: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h. 486"
                },
                "489": {
                    "answer": "The LLMs we recommend you use are: Med-Flamingo-7B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 489"
                },
                "490": {
                    "answer": "The LLMs we recommend you use are: Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*). Here are the required resources:<br> <br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>. 490"
                },
                "493": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 500W and the total price is $13998.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPU is 250W and the total price is $6999.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The total thermal design power of the GPU is 350W and the total price is $1600.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 493"
                },
                "494": {
                    "answer": "The LLMs we recommend you use are: GatorTron-345M (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*),  GestaltGPT-7B (*), Clinical-longformer-150M (*), BioClinRoBERTa-345M (*), Me LLaMA-Chat-70B (*), Me LLaMA-70B (*), BioBERT (*), GPT2-1.5B (*), BioLinkBERT (*), ClinicalBERT-110M (*), RadioLOGIC (*). Here are the required resources:<br><br>GatorTron-345M: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting this type of GPU using cloud services is $4.05/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>GestaltGPT-7B: no specific resource requirements for this model, refer to resources for LLMs of similar size (7B). Fine-tuning requires 2 NVIDIA TESLA A100-40GB GPU. The price of renting 2 this type of GPU using cloud services is $8.1/1h.<br> <br>It can be accessed via link <a href='https://github.com/WGLab/GestaltMML-GestaltGPT' target='_blank'>GestaltGPT GitHub</a>.<br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>BioBERT: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>GPT2-1.5B: fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>BioLinkBERT: no specific resource requirements for this model, refer to resources for BERT. fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br> <br>Inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br> <br>ClinicalBERT-110M: inference requires 1 NVIDIA GTX 3090-24GB GPU. The price of renting a GPU with 24GB of memory using a cloud service is $1.88/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>. 494"
                },
                "495": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.  495"
                },
                "496": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  496"
                },
                "497": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 497"
                },
                "498": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*). Here are the required resources:<br><br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>. 498"
                },
                "499": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  499"
                },
                "500": {
                    "answer": "The LLM we recommend you use is: LLaMA-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.  500"
                },
                "501": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>GatorTronS-20B: no specific resource requirements for these models, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br> <br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The total thermal design power of the GPUs is 295W and the total price is $4300.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $4680.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 501"
                },
                "502": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), LLaMA-7B (*), Vicuna-13B (*),  Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), Alpaca-7B (*), RadioLOGIC (*), PhenoBCBERT-110M (*), PhenoGPT-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>Vicuna-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $128.6/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>Alpaca-7B: fine-tuning requires 1 NVIDIA Quadro RTX 8000 GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>RadioLOGIC: pre-train requires 1 NVIDIA RTX A6000-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/Netherlands-Cancer-Institute/RadioLOGIC_NLP' target='_blank'>RadioLOGIC GitHub</a>.<br><br>PhenoBCBERT-110M: fine-tuning requires 1 2GB GPU. The price of renting a GPU with 2GB of memory using a cloud service is $0.16/1h.<br><br>PhenoGPT-7B: fine-tuning requires 1 70GB GPU. The price of renting a GPU with 70GB of memory using a cloud service is $5.47/1h.<br><br>It can be accessed via link <a href='https://github.com/WGLab/PhenoGPT' target='_blank'>PhenoGPT GitHub</a>. 502"
                },
                "503": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 503"
                },
                "504": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br> <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 504"
                },
                "505": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 297600W and the total price is $17856000. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 8000W and the total price is $223968.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $12588.<br><br>GatorTronGPT-20B: fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The total thermal design power of the GPUs is 250W and the total price is $6999.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $51429.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPU is 2400W and the total price is $360000.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The total thermal design power of the GPU is 300W and the total price is $7799.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 2000W and the total price is $55992.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $20571.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPUs is 2400W and the total price is $144000.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The total thermal design power of the GPUs is 300W and the total price is $18000.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The total thermal design power of the GPU is 9600W and the total price is $576000.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPU is 2000W and the total price is $55992. 505"
                },
                "506": {
                    "answer": "The LLMs we recommend you use are: GatorTron-8.9B (*), MedAlpaca-13B (*), Clinical-longformer-150M (*), GatorTronGPT-20B (*), GatorTronS-20B (*), BioClinRoBERTa-345M (*), Galactica-120B (*), Me LLaMA-Chat-13B (*), Me LLaMA-Chat-70B (*), Me LLaMA-13B (*), Me LLaMA-70B (*), RaDialog-7B (*), ChatDoctor-7B (*), MedChatZH-7B (*), Med-Flamingo-9B (*), SkinGPT-4-40B (*), RadFM-14B (*), LLaVA-Med-7B (*). Here are the required resources:<br> <br>GatorTron-8.9B: pre-train requires 992 NVIDIA TESLA A100-80GB GPUs. The price of renting 992 this type of GPU using cloud services is $6200/1h. The data is only reported in the paper, and an LLM of that size may only require a few dozen GPUs of the same type.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>MedAlpaca-13B: no specific resource requirements for this model, refer to resources for LLMs of similar size (13B). Pre-train requires 32 NVIDIA TESLA A100-40GB GPUs. The price of renting 32 this type of GPU using cloud services is $129.6/1h.<br><br>Clinical-longformer-150M: pre-train requires 6 NVIDIA TESLA V100-32GB GPUs. The price of renting 6 this type of GPU using cloud services is $29.76/1h.<br><br>GatorTronGPT-20B: pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>GatorTronS-20B: no specific resource requirements for this model, refer to resources for LLMs of similar size (20B). Pre-train requires 560 NVIDIA TESLA A100-80GB GPUs. The price of renting 560 this type of GPU using cloud services is $3500/1h.<br><br>Fine-tuning requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br> <br>It can be accessed via link <a href='https://github.com/NVIDIA/Megatron-LM' target='_blank'>GatorTron1 GitHub</a> and <a href='https://github.com/NVIDIA/NeMo' target='_blank'>GatorTron2 GitHub</a>.<br><br>BioClinRoBERTa-345M: no specific resource requirements for this model, refer to resources for LLMs of similar size (406M). Fine-tuning requires 1 NVIDIA TESLA A100-40GB GPU. The price of renting 1 this type of GPU using cloud services is $4.05/1h.<br><br>Galactica-120B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires more than 120 NVIDIA TESLA A100-80GB GPUs. The price of renting 120 this type of GPU using cloud services is $750/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Me LLaMA-Chat-13B, Me LLaMA-13B, Me LLaMA-Chat-70B and Me LLaMA-70B: pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 GPUs of this type using cloud services is $1760/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 GPUs of this type using cloud services is $88/1h.<br><br>They can be accessed via link <a href='https://github.com/BIDS-Xu-Lab/Me-LLaMA' target='_blank'>MeLLaMA GitHub</a>.<br><br>RaDialog-7B: fine-tuning requires 1 NVIDIA A40-48GB GPU. The price of renting a GPU with 48GB of memory using a cloud service is $3.75/1h.<br><br>It can be accessed via link <a href='https://github.com/ChantalMP/RaDialog' target='_blank'>RaDialog GitHub</a>.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>.<br><br>MedChatZH-7B: pre-train requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>Fine-tuning  requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 8 this type of GPU using cloud services is $32.4/1h.<br><br>It can be accessed via link <a href='https://github.com/tyang816/MedChatZH' target='_blank'>MedChatZH GitHub</a>.<br><br>Med-Flamingo-9B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>It can be accessed via link <a href='https://github.com/snap-stanford/med-flamingo' target='_blank'>MedFlamingo GitHub</a>.<br><br>SkinGPT-4-40B: pre-train requires 8 NVIDIA TESLA A100-80GB GPUs. The price of renting 8 this type of GPU using cloud services is $50/1h.<br><br>Inference requires 1 NVIDIA TESLA A100-80GB GPU. The price of renting 1 this type of GPU using cloud services is $6.25/1h.<br><br>It can be accessed via link <a href='https://github.com/JoshuaChou2018/SkinGPT-4' target='_blank'>SkinGPT4 GitHub</a>.<br><br>RadFM-14B: pre-train requires 32 NVIDIA TESLA A100-80GB GPUs. The price of renting 32 this type of GPU using cloud services is $200/1h.<br><br>It can be accessed via link <a href='https://github.com/chaoyi-wu/RadFM' target='_blank'>RadFM GitHub</a>.<br><br>LLaVA-Med-7B: fine-tuning requires 8 NVIDIA TESLA A100-40GB GPUs. The price of renting 1 this type of GPU using cloud services is $32.4/1h. 506"
                },
                "507": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 500W and the total price is $13998. Inference requires 1 80GB GPU.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Fine-tuning requires 8 H100 GPUs. The total thermal design power of the GPUs is 2400W and the total price is $360000.<br><br>Inference requires 2 NVIDIA A40 GPUs. The total thermal design power of the GPUs is 600W and the total price is $15998.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The total thermal design power of the GPUs is 1500W and the total price is $41994.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 507"
                },
                "508": {
                    "answer": "The LLMs we recommend you use are: LLaMA-7B, LLaMA-70B, ChatDoctor-7B. Here are the required resources:<br>  <br>LLaMA-7B: fine-tuning requires 2 NVIDIA TESLA A100-40GB GPUs. The price of renting 2 this type of GPU using cloud services is $8.1/1h. Inference requires 1 80GB GPU. The price of renting a GPU with 80GB of memory using a cloud service is $6.25/1h.<br><br>LLaMA-70B: no specific resource requirements for this model, refer to resources for LLMs of similar size (70B). Pre-train requires 160 NVIDIA TESLA A100-80GB GPUs. The price of renting 160 this type of GPU using cloud services is $1000/1h.<br><br>Fine-tuning requires 8 H100 GPUs. The price of renting 8 this type of GPU using cloud services is $88/1h.<br><br>Inference requires 2 NVIDIA A40 GPUs. The price of renting GPUs with 96GB of memory using a cloud service is $7.5/1h.<br><br>ChatDoctor-7B: fine-tuning requires 6 NVIDIA TESLA A100-40GB GPUs. The price of renting 6 this type of GPU using cloud services is $24.3/1h.<br><br>It can be accessed via link <a href='https://github.com/Kent0n-Li/ChatDoctor' target='_blank'>ChatDoctor GitHub</a>. 508"
                }
            }
            ;

            let currentNode = "0"; // Starting node
            let questionHistory = []; // Keeps track of answered questions

            // Function to display a question based on the node
            function displayQuestion(node, questionIndex) {
                const questionContainer = document.getElementById('questionContainer');
                // Clear questions beyond this index
                questionContainer.innerHTML = '';

                // Display history
                questionHistory.slice(0, questionIndex).forEach(q => appendQuestion(q.node, q.choice, q.number));

                // Display the current question
                appendQuestion(node, null, questionIndex + 1);
            }

            function appendQuestion(node, selectedChoice, questionNumber) {
                const questionContainer = document.getElementById('questionContainer');

                if (data[node] && data[node].question) {
                    const questionDiv = document.createElement('div');
                    questionDiv.classList.add('question');

                    // Display fixed question number
                    const questionNumberElem = document.createElement('p');
                    questionNumberElem.classList.add('questionNumber');
                    questionNumberElem.innerText = `Question ${questionNumber}:`;
                    questionDiv.appendChild(questionNumberElem);

                    // Display question text
                    const questionText = document.createElement('p');
                    questionText.innerText = data[node].question;
                    questionDiv.appendChild(questionText);

                    // Create Yes button
                    const yesButton = document.createElement('button');
                    yesButton.innerText = 'Yes';
                    yesButton.classList.toggle('selected', selectedChoice === 'yes');
                    yesButton.onclick = function () {
                        updateHistory(node, 'yes', questionNumber);
                        currentNode = data[node].yes;
                        displayQuestion(currentNode, questionNumber);
                    };
                    questionDiv.appendChild(yesButton);

                    // Create No button
                    const noButton = document.createElement('button');
                    noButton.innerText = 'No';
                    noButton.classList.toggle('selected', selectedChoice === 'no');
                    noButton.onclick = function () {
                        updateHistory(node, 'no', questionNumber);
                        currentNode = data[node].no;
                        displayQuestion(currentNode, questionNumber);
                    };
                    questionDiv.appendChild(noButton);

                    // Append the question block to the container
                    questionContainer.appendChild(questionDiv);

                } else if (data[node] && data[node].answer) {
                    // Create a div for the final answer
                    const answerDiv = document.createElement('div');
                    answerDiv.classList.add('answer');

                    const answerText = document.createElement('p');
                    answerText.innerHTML = data[node].answer;  // Allow HTML content for line breaks and links
                    answerDiv.appendChild(answerText);

                    // Append the answer to the container
                    questionContainer.appendChild(answerDiv);
                } else {
                    // Handle if no more questions or no data found
                    const noMoreQuestions = document.createElement('p');
                    noMoreQuestions.innerText = "No more questions or answers.";
                    questionContainer.appendChild(noMoreQuestions);
                }
            }

            function updateHistory(node, choice, questionNumber) {
                // Check if we are revisiting a question and modify history accordingly
                const historyIndex = questionHistory.findIndex(q => q.number === questionNumber);
                if (historyIndex !== -1) {
                    questionHistory = questionHistory.slice(0, historyIndex); // Remove subsequent questions
                }

                // Add current question to history
                questionHistory.push({ node, choice, number: questionNumber });
            }

            // Start the first question
            displayQuestion(currentNode, 0);
        });
    </script>
</body>
</html>
